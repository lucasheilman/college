heilma1@cumulus:~/PDC/lab12$ jar cvf WordCount.jar -C classes edu
added manifest
adding: edu/(in = 0) (out= 0)(stored 0%)
adding: edu/stolaf/(in = 0) (out= 0)(stored 0%)
adding: edu/stolaf/cs/(in = 0) (out= 0)(stored 0%)
adding: edu/stolaf/cs/WordCount$Reduce.class(in = 1619) (out= 652)(deflated 59%)
adding: edu/stolaf/cs/WordCount.class(in = 1526) (out= 739)(deflated 51%)
adding: edu/stolaf/cs/WordCount$Map.class(in = 1883) (out= 791)(deflated 57%)
heilma1@cumulus:~/PDC/lab12$ hadoop jar WordCount.jar edu.stolaf.cs.WordCounr mice wc-out1
Exception in thread "main" java.lang.ClassNotFoundException: edu.stolaf.cs.WordCounr
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:247)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:149)
heilma1@cumulus:~/PDC/lab12$ hadoop fs -ls wc-out1
ls: Cannot access wc-out1: No such file or directory.
heilma1@cumulus:~/PDC/lab12$ javac -classpath /usr/lib/hadoop/hadoop-0.20.1-core.jar -d classes WordCount.java
Note: WordCount.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
heilma1@cumulus:~/PDC/lab12$ jar cvf WordCount.jar -C classes edu
added manifest
adding: edu/(in = 0) (out= 0)(stored 0%)
adding: edu/stolaf/(in = 0) (out= 0)(stored 0%)
adding: edu/stolaf/cs/(in = 0) (out= 0)(stored 0%)
adding: edu/stolaf/cs/WordCount$Reduce.class(in = 1619) (out= 652)(deflated 59%)
adding: edu/stolaf/cs/WordCount.class(in = 1526) (out= 739)(deflated 51%)
adding: edu/stolaf/cs/WordCount$Map.class(in = 1883) (out= 791)(deflated 57%)
heilma1@cumulus:~/PDC/lab12$ hadoop jar WordCount.jar edu.stolaf.cs.WordCount mice wc-out1
16/11/15 22:20:17 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
16/11/15 22:20:17 INFO mapred.FileInputFormat: Total input paths to process : 1
16/11/15 22:20:17 INFO mapred.JobClient: Running job: job_201611121116_0433
16/11/15 22:20:18 INFO mapred.JobClient:  map 0% reduce 0%
16/11/15 22:20:27 INFO mapred.JobClient:  map 100% reduce 0%
16/11/15 22:20:39 INFO mapred.JobClient:  map 100% reduce 100%
16/11/15 22:20:41 INFO mapred.JobClient: Job complete: job_201611121116_0433
16/11/15 22:20:41 INFO mapred.JobClient: Counters: 18
16/11/15 22:20:41 INFO mapred.JobClient:   Job Counters 
16/11/15 22:20:41 INFO mapred.JobClient:     Launched reduce tasks=1
16/11/15 22:20:41 INFO mapred.JobClient:     Rack-local map tasks=2
16/11/15 22:20:41 INFO mapred.JobClient:     Launched map tasks=2
16/11/15 22:20:41 INFO mapred.JobClient:   FileSystemCounters
16/11/15 22:20:41 INFO mapred.JobClient:     FILE_BYTES_READ=490
16/11/15 22:20:41 INFO mapred.JobClient:     HDFS_BYTES_READ=331
16/11/15 22:20:41 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=1050
16/11/15 22:20:41 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=261
16/11/15 22:20:41 INFO mapred.JobClient:   Map-Reduce Framework
16/11/15 22:20:41 INFO mapred.JobClient:     Reduce input groups=37
16/11/15 22:20:41 INFO mapred.JobClient:     Combine output records=0
16/11/15 22:20:41 INFO mapred.JobClient:     Map input records=6
16/11/15 22:20:41 INFO mapred.JobClient:     Reduce shuffle bytes=496
16/11/15 22:20:41 INFO mapred.JobClient:     Reduce output records=37
16/11/15 22:20:41 INFO mapred.JobClient:     Spilled Records=88
16/11/15 22:20:41 INFO mapred.JobClient:     Map output bytes=396
16/11/15 22:20:41 INFO mapred.JobClient:     Map input bytes=220
16/11/15 22:20:41 INFO mapred.JobClient:     Combine input records=0
16/11/15 22:20:41 INFO mapred.JobClient:     Map output records=44
16/11/15 22:20:41 INFO mapred.JobClient:     Reduce input records=44
heilma1@cumulus:~/PDC/lab12$ hadoop fs -ls wc-out1
Found 1 items
-rw-r--r--   3 heilma1 supergroup        261 2016-11-15 22:20 /user/heilma1/wc-out1/part-00000
heilma1@cumulus:~/PDC/lab12$ hadoop fs -cat wc-out1/part-00000 | more
As	1
Did	1
See	1
She	1
They	1
Three	1
a	2
after	1
all	1
blind	3
carving	1
cut	1
ever	1
farmer's	1
how	2
in	1
knife.	1
life	1
mice!	1
heilma1@cumulus:~/PDC/lab12$ 

heilma1@cumulus:~/PDC/lab12$ touch WordCount.java
heilma1@cumulus:~/PDC/lab12$ make WordCount.hadoop DATA=mice
cat: .lasttarget: No such file or directory
cat: .lasttarget: No such file or directory
rm -rf classes/*
javac -classpath /usr/lib/hadoop/hadoop-0.20.1-core.jar    -d classes  WordCount.java
Note: WordCount.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
jar cvf WordCount.jar -C classes edu
added manifest
adding: edu/(in = 0) (out= 0)(stored 0%)
adding: edu/stolaf/(in = 0) (out= 0)(stored 0%)
adding: edu/stolaf/cs/(in = 0) (out= 0)(stored 0%)
adding: edu/stolaf/cs/WordCount$Reduce.class(in = 1619) (out= 652)(deflated 59%)
adding: edu/stolaf/cs/WordCount.class(in = 1526) (out= 739)(deflated 51%)
adding: edu/stolaf/cs/WordCount$Map.class(in = 1883) (out= 791)(deflated 57%)
echo mice >> .lastjob.DATA
echo out >> .lastjob.OUTPARENT
echo ===== JOB 4963 ===== ; echo WordCount.4963 > .lastjob ; echo WordCount > .lasttarget ;  echo mice > .lastjob.DATA ; echo mice > .lastjob.WordCount.DATA ;       \
	hadoop jar WordCount.jar edu.stolaf.cs.WordCount mice out/WordCount.4963 \
	     && echo WordCount.4963 > .lastjob.WordCount ; echo out/WordCount.4963 > .lastjob.WordCount.OUTDIR ; 
===== JOB 4963 =====
16/11/15 22:24:54 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
16/11/15 22:24:55 INFO mapred.FileInputFormat: Total input paths to process : 1
16/11/15 22:24:55 INFO mapred.JobClient: Running job: job_201611121116_0442
16/11/15 22:24:56 INFO mapred.JobClient:  map 0% reduce 0%
16/11/15 22:25:04 INFO mapred.JobClient:  map 100% reduce 0%
16/11/15 22:25:16 INFO mapred.JobClient:  map 100% reduce 100%
16/11/15 22:25:18 INFO mapred.JobClient: Job complete: job_201611121116_0442
16/11/15 22:25:18 INFO mapred.JobClient: Counters: 19
16/11/15 22:25:18 INFO mapred.JobClient:   Job Counters 
16/11/15 22:25:18 INFO mapred.JobClient:     Launched reduce tasks=1
16/11/15 22:25:18 INFO mapred.JobClient:     Rack-local map tasks=1
16/11/15 22:25:18 INFO mapred.JobClient:     Launched map tasks=2
16/11/15 22:25:18 INFO mapred.JobClient:     Data-local map tasks=1
16/11/15 22:25:18 INFO mapred.JobClient:   FileSystemCounters
16/11/15 22:25:18 INFO mapred.JobClient:     FILE_BYTES_READ=490
16/11/15 22:25:18 INFO mapred.JobClient:     HDFS_BYTES_READ=331
16/11/15 22:25:18 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=1050
16/11/15 22:25:18 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=261
16/11/15 22:25:18 INFO mapred.JobClient:   Map-Reduce Framework
16/11/15 22:25:18 INFO mapred.JobClient:     Reduce input groups=37
16/11/15 22:25:18 INFO mapred.JobClient:     Combine output records=0
16/11/15 22:25:18 INFO mapred.JobClient:     Map input records=6
16/11/15 22:25:18 INFO mapred.JobClient:     Reduce shuffle bytes=242
16/11/15 22:25:18 INFO mapred.JobClient:     Reduce output records=37
16/11/15 22:25:18 INFO mapred.JobClient:     Spilled Records=88
16/11/15 22:25:18 INFO mapred.JobClient:     Map output bytes=396
16/11/15 22:25:18 INFO mapred.JobClient:     Map input bytes=220
16/11/15 22:25:18 INFO mapred.JobClient:     Combine input records=0
16/11/15 22:25:18 INFO mapred.JobClient:     Map output records=44
16/11/15 22:25:18 INFO mapred.JobClient:     Reduce input records=44
heilma1@cumulus:~/PDC/lab12$ make print | more
hadoop fs -cat out/WordCount.4963/part-00000
As	1
Did	1
See	1
She	1
They	1
Three	1
a	2
after	1
all	1
blind	3
carving	1
cut	1
ever	1
farmer's	1
how	2
in	1
knife.	1
life	1

heilma1@cumulus:~/PDC/lab12$ time make WordCountValue.hadoop DATA=mice2
rm -rf classes/*
javac -classpath /usr/lib/hadoop/hadoop-0.20.1-core.jar    -d classes  WordCountValue.java
Note: WordCountValue.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
jar cvf WordCountValue.jar -C classes edu
added manifest
adding: edu/(in = 0) (out= 0)(stored 0%)
adding: edu/stolaf/(in = 0) (out= 0)(stored 0%)
adding: edu/stolaf/cs/(in = 0) (out= 0)(stored 0%)
adding: edu/stolaf/cs/WordCountValue.class(in = 1546) (out= 742)(deflated 52%)
adding: edu/stolaf/cs/WordCountValue$Map.class(in = 1898) (out= 794)(deflated 58%)
adding: edu/stolaf/cs/WordCountValue$Reduce.class(in = 1634) (out= 656)(deflated 59%)
echo ===== JOB 1329 ===== ; echo WordCountValue.1329 > .lastjob ; echo WordCountValue > .lasttarget ;  echo mice2 > .lastjob.DATA ; echo mice2 > .lastjob.WordCountValue.DATA ;       \
     hadoop jar WordCountValue.jar edu.stolaf.cs.WordCountValue mice2 out/WordCountValue.1329 \
          && echo WordCountValue.1329 > .lastjob.WordCountValue ; echo out/WordCountValue.1329 > .lastjob.WordCountValue.OUTDIR ; 
===== JOB 1329 =====
16/12/08 19:33:12 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
16/12/08 19:33:12 INFO mapred.FileInputFormat: Total input paths to process : 1
16/12/08 19:33:12 INFO mapred.JobClient: Running job: job_201611182133_0429
16/12/08 19:33:13 INFO mapred.JobClient:  map 0% reduce 0%
16/12/08 19:33:23 INFO mapred.JobClient:  map 100% reduce 0%
16/12/08 19:33:35 INFO mapred.JobClient:  map 100% reduce 100%
16/12/08 19:33:37 INFO mapred.JobClient: Job complete: job_201611182133_0429
16/12/08 19:33:37 INFO mapred.JobClient: Counters: 19
16/12/08 19:33:37 INFO mapred.JobClient:   Job Counters 
16/12/08 19:33:37 INFO mapred.JobClient:     Launched reduce tasks=1
16/12/08 19:33:37 INFO mapred.JobClient:     Rack-local map tasks=1
16/12/08 19:33:37 INFO mapred.JobClient:     Launched map tasks=2
16/12/08 19:33:37 INFO mapred.JobClient:     Data-local map tasks=1
16/12/08 19:33:37 INFO mapred.JobClient:   FileSystemCounters
16/12/08 19:33:37 INFO mapred.JobClient:     FILE_BYTES_READ=490
16/12/08 19:33:37 INFO mapred.JobClient:     HDFS_BYTES_READ=394
16/12/08 19:33:37 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=1050
16/12/08 19:33:37 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=261
16/12/08 19:33:37 INFO mapred.JobClient:   Map-Reduce Framework
16/12/08 19:33:37 INFO mapred.JobClient:     Reduce input groups=37
16/12/08 19:33:37 INFO mapred.JobClient:     Combine output records=0
16/12/08 19:33:37 INFO mapred.JobClient:     Map input records=6
16/12/08 19:33:37 INFO mapred.JobClient:     Reduce shuffle bytes=496
16/12/08 19:33:37 INFO mapred.JobClient:     Reduce output records=37
16/12/08 19:33:37 INFO mapred.JobClient:     Spilled Records=88
16/12/08 19:33:37 INFO mapred.JobClient:     Map output bytes=396
16/12/08 19:33:37 INFO mapred.JobClient:     Map input bytes=262
16/12/08 19:33:37 INFO mapred.JobClient:     Combine input records=0
16/12/08 19:33:37 INFO mapred.JobClient:     Map output records=44
16/12/08 19:33:37 INFO mapred.JobClient:     Reduce input records=44

real	 0m26.595s
user	 0m3.188s
sys	 0m0.484s
heilma1@cumulus:~/PDC/lab12$ time make hadoop DATA=lab10
echo ===== JOB 1438 ===== ; echo WordCountValue.1438 > .lastjob ; echo WordCountValue > .lasttarget ;  echo lab10 > .lastjob.DATA ; echo lab10 > .lastjob.WordCountValue.DATA ;       \
     hadoop jar WordCountValue.jar edu.stolaf.cs.WordCountValue lab10 out/WordCountValue.1438 \
          && echo WordCountValue.1438 > .lastjob.WordCountValue ; echo out/WordCountValue.1438 > .lastjob.WordCountValue.OUTDIR ; 
===== JOB 1438 =====
16/12/08 19:33:47 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
Exception in thread "main" org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://cumulus/user/heilma1/lab10
	  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:190)
	  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:201)
	  at org.apache.hadoop.mapred.JobClient.writeOldSplits(JobClient.java:810)
	  at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:781)
	  at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:730)
	  at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1249)
	  at edu.stolaf.cs.WordCountValue.main(WordCountValue.java:34)
	  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	  at java.lang.reflect.Method.invoke(Method.java:597)
	  at org.apache.hadoop.util.RunJar.main(RunJar.java:156)

real	  0m1.105s
user	  0m1.204s
sys	  0m0.216s
heilma1@cumulus:~/PDC/lab12$ 
